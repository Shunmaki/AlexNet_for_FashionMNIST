{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c5601b5-f5b3-4151-8b32-42cc68589c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import mylib.model_implementation as model_implementation\n",
    "import mylib.make_dataloader as make_dataloader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a208ea0e-4395-4bd8-811c-a2d9fed26dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 2\n",
    "train_loss_list, train_acc_list, val_loss_list, val_acc_list = [], [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de50f880-6a9a-4e6b-a04b-6d1da2f8d9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62fd3267-376d-43a7-a3c2-59852c89ad58",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_implementation.cifar10_alexnet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e359643-fdab-4679-ae3d-d021eefb4c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48f4aa57-8bb4-47f9-b591-34bb9f16c2c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_loader = make_dataloader.make_train_loader()\n",
    "test_loader = make_dataloader.make_test_loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9d10f2-a087-4eb5-b615-8860cff0a8e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/782 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "### training\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc, val_loss, val_acc = 0.0, 0.0, 0.0, 0.0\n",
    "    \n",
    "    # ====== train_mode ======\n",
    "    model.train()\n",
    "    for i, (images, labels) in enumerate(tqdm(train_loader)):\n",
    "      images, labels = images.to(device), labels.to(device)      \n",
    "      optimizer.zero_grad()\n",
    "      outputs = model(images)\n",
    "      loss = criterion(outputs, labels)\n",
    "      train_loss += loss.item()\n",
    "      train_acc += (outputs.max(1)[1] == labels).sum().item()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "    \n",
    "    avg_train_loss = train_loss / len(train_loader.dataset)\n",
    "    avg_train_acc = train_acc / len(train_loader.dataset)\n",
    "    \n",
    "    # ====== val_mode ======\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "      for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        val_loss += loss.item()\n",
    "        val_acc += (outputs.max(1)[1] == labels).sum().item()\n",
    "    avg_val_loss = val_loss / len(test_loader.dataset)\n",
    "    avg_val_acc = val_acc / len(test_loader.dataset)\n",
    "    \n",
    "    print ('Epoch [{}/{}], Loss: {loss:.4f}, val_loss: {val_loss:.4f}, val_acc: {val_acc:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, loss=avg_train_loss, val_loss=avg_val_loss, val_acc=avg_val_acc))\n",
    "    train_loss_list.append(avg_train_loss)\n",
    "    train_acc_list.append(avg_train_acc)\n",
    "    val_loss_list.append(avg_val_loss)\n",
    "    val_acc_list.append(avg_val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa790ddc-afdc-4436-8c08-efbc484c97f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/Users/makishunsuke/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/Users/makishunsuke/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 58, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/Users/makishunsuke/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 58, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/Users/makishunsuke/opt/anaconda3/lib/python3.9/site-packages/torchvision/datasets/cifar.py\", line 118, in __getitem__\n    img = self.transform(img)\nTypeError: __init__() takes 1 positional argument but 2 were given\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (images, labels) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m      2\u001b[0m     printi()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1333\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1332\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1333\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1359\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1357\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1359\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1360\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/_utils.py:543\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    540\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    541\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    542\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m--> 543\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mTypeError\u001b[0m: Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/Users/makishunsuke/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/Users/makishunsuke/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 58, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/Users/makishunsuke/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 58, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/Users/makishunsuke/opt/anaconda3/lib/python3.9/site-packages/torchvision/datasets/cifar.py\", line 118, in __getitem__\n    img = self.transform(img)\nTypeError: __init__() takes 1 positional argument but 2 were given\n"
     ]
    }
   ],
   "source": [
    "for i, (images, labels) in enumerate(train_loader):\n",
    "    printi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf79c52e-462e-4394-82a5-bcd55ffe5a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in (train_loader):\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19aec405-b2bc-4934-a022-4ffd20608e02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
